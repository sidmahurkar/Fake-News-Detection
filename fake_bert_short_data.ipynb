{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fake bert short data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHJsoYsLWkkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## import all the required libraries for preprocessing and computation\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeN0njpyXwEO",
        "colab_type": "code",
        "outputId": "329cd07e-1f74-4eaa-d552-0a4594557cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiPiVWvgXyvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### DATASETS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6D0TPe0YA5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### LIAR\n",
        "# Loading the Liar Dataset train set file\n",
        "url = 'https://raw.githubusercontent.com/nishitpatel01/Fake_News_Detection/master/train.csv'\n",
        "liar_df_train = pd.read_csv(url, error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE5VccRGYKt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexNames = liar_df_train[liar_df_train['Statement'].apply(len) > 256].index\n",
        "liar_df_train.drop(indexNames , inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NMO0jhSYOrF",
        "colab_type": "code",
        "outputId": "47dc78a6-2b44-45a9-a6d8-5aa461c40dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "liar_df_train['Label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     5719\n",
              "False    4465\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Kd5-pyYRDb",
        "colab_type": "code",
        "outputId": "ae40d7e7-bd70-4eb4-89db-206a9f03b72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "liar_df_train = liar_df_train[['Statement','Label']]\n",
        "liar_df_train.columns = ['text','label']\n",
        "liar_df_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfYXB-PgYU1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "liar_df_train.loc[liar_df_train['label'] == True, 'label'] = 'REAL'\n",
        "liar_df_train.loc[liar_df_train['label'] == False, 'label'] = 'FAKE'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XElLIJNcYXzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the Liar Dataset validation set file\n",
        "url = 'https://raw.githubusercontent.com/nishitpatel01/Fake_News_Detection/master/valid.csv'\n",
        "liar_df_valid = pd.read_csv(url, error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljfMMq3Qiks5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexNames = liar_df_valid[liar_df_valid['Statement'].apply(len) > 256].index\n",
        "liar_df_valid.drop(indexNames , inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk-Rh_kxYbIW",
        "colab_type": "code",
        "outputId": "0b321c99-177d-4bf0-9119-dcdf9fd23dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "liar_df_valid.columns = ['text','label']\n",
        "liar_df_valid.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0fE34KUYdZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "liar_df_valid.loc[liar_df_valid['label'] == 'TRUE', 'label'] = 'REAL'\n",
        "liar_df_valid.loc[liar_df_valid['label'] == 'FALSE', 'label'] = 'FAKE'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZcBojoBYh6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the liar Dataset test set file\n",
        "url = 'https://raw.githubusercontent.com/nishitpatel01/Fake_News_Detection/master/test.csv'\n",
        "liar_df_test = pd.read_csv(url, error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpISrFNRYkxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "liar_df_test.drop(liar_df_test[liar_df_test['Statement'].apply(len) > 256].index, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rQCqWj7Yobk",
        "colab_type": "code",
        "outputId": "1655f6c8-1fea-42a8-af62-2dfef34bbe5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "liar_df_test.columns = ['text','label']\n",
        "liar_df_test.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsDPzHqNYtcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "liar_df_test.loc[liar_df_test['label'] == True, 'label'] = 'REAL'\n",
        "liar_df_test.loc[liar_df_test['label'] == False, 'label'] = 'FAKE'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_dBQb5fYycn",
        "colab_type": "code",
        "outputId": "66d3e033-8a26-4a15-f6e8-b721347f440f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "liar_df_test['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "REAL    1371\n",
              "FAKE    1167\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFm1QyfJY0eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the George McItyre Dataset\n",
        "# fake_or_real_news.csv\n",
        "url = 'https://raw.githubusercontent.com/lutzhamel/fake-news/master/data/fake_or_real_news.csv'\n",
        "george_df = pd.read_csv(url, error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4NuvCmcjnoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexNames = george_df[george_df['title'].apply(len) > 256].index\n",
        "george_df.drop(indexNames , inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVGG1mjbZZyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Fake News Dataset from kaggle\n",
        "fnd_df = pd.read_csv('/content/gdrive/My Drive/fake_news_data_kaggle.csv',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPtx5I8wZk38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnd_df.drop(fnd_df[fnd_df['Headline'].apply(len) > 256].index, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZTuCF_wZni2",
        "colab_type": "code",
        "outputId": "f62a02ba-139b-41cc-af3f-89f0f4ec4543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(fnd_df.Headline.map(lambda x: len(x)).max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MscQQMnSZpW4",
        "colab_type": "code",
        "outputId": "98438fc2-630b-463c-b66d-15742c0101c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "##### Processing \n",
        "george_df = george_df[['title','text','label']]\n",
        "george_df.columns\n",
        "george_df['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "REAL    3171\n",
              "FAKE    3162\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1crONgiZ0qR",
        "colab_type": "code",
        "outputId": "3981b30a-69ef-4e8e-e7ad-3ab7ed190c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#### 4. Fake News Kaggle Dataset\n",
        "fnd_df.tail()\n",
        "fnd_df.loc[fnd_df['Label']== 0, 'Label'] = 'REAL'\n",
        "fnd_df.loc[fnd_df['Label']== 1, 'Label'] = 'FAKE'\n",
        "fnd_df.columns\n",
        "fnd_df['Label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "REAL    2134\n",
              "FAKE    1872\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPZnATwjaATP",
        "colab_type": "code",
        "outputId": "ebe52cd8-8b0c-4419-9bae-4154ae3cbdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Dropping the column URLs from the table\n",
        "fnd_df.drop(['URLs'], axis = 1, inplace = True)\n",
        "fnd_df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Headline', 'Body', 'Label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYNt9IRPaCRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnd_df.columns = ['title', 'text', 'label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA7eInfiaEmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### 1. LIAR Dataset\n",
        "liar_df_train = liar_df_train.append(liar_df_valid, ignore_index = True)\n",
        "liar_df_train = liar_df_train.append(liar_df_test, ignore_index = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI4OCNzcaJNY",
        "colab_type": "code",
        "outputId": "74acb4f1-604d-4837-9075-efe43ee7e70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "liar_df_train['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "REAL     8416\n",
              "FAKE     6862\n",
              "Label       1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOJU8iKXaL7O",
        "colab_type": "code",
        "outputId": "e0d74959-3f60-4b66-8cef-df6a0e0a2a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "### Cancatenating the datasets\n",
        "fnd_df = fnd_df.append(george_df, ignore_index = True)\n",
        "fnd_df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10334</th>\n",
              "      <td>State Department says it can't find emails fro...</td>\n",
              "      <td>The State Department told the Republican Natio...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10335</th>\n",
              "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
              "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10336</th>\n",
              "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
              "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10337</th>\n",
              "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
              "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10338</th>\n",
              "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
              "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ... label\n",
              "10334  State Department says it can't find emails fro...  ...  REAL\n",
              "10335  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  ...  FAKE\n",
              "10336  Anti-Trump Protesters Are Tools of the Oligarc...  ...  FAKE\n",
              "10337  In Ethiopia, Obama seeks progress on peace, se...  ...  REAL\n",
              "10338  Jeb Bush Is Suddenly Attacking Trump. Here's W...  ...  REAL\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxHJtWDradBn",
        "colab_type": "code",
        "outputId": "e5e83524-5236-4e27-a140-12e2469596dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(fnd_df.title.map(lambda x: len(x)).max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb0RFVo7ahHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taking only the title part of the dataframe\n",
        "fnd_df = fnd_df[['title','label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FNUpKPSamCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changing the column so that it can concatenate with other dataframes\n",
        "liar_df_train.columns = ['title','label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ--wD2ganuw",
        "colab_type": "code",
        "outputId": "624b3754-6e0b-486e-878f-f450a34bf7db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# Concatenate the liar and the other previous datasets.\n",
        "fnd_df = fnd_df.append(liar_df_train, ignore_index = True)\n",
        "fnd_df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25615</th>\n",
              "      <td>For the first time in more than a decade, impo...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25616</th>\n",
              "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25617</th>\n",
              "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25618</th>\n",
              "      <td>A new poll shows 62 percent support the presid...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25619</th>\n",
              "      <td>No one claims the report vindicating New Jerse...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title label\n",
              "25615  For the first time in more than a decade, impo...  REAL\n",
              "25616  Says Donald Trump has bankrupted his companies...  REAL\n",
              "25617  John McCain and George Bush have \"absolutely n...  REAL\n",
              "25618  A new poll shows 62 percent support the presid...  FAKE\n",
              "25619  No one claims the report vindicating New Jerse...  FAKE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C520vcu7aqZv",
        "colab_type": "code",
        "outputId": "9258fddb-def4-418d-ce24-0802eb5cc338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "####### Algo and Computation\n",
        "\n",
        "# Check if GPU is Available or Not.\n",
        "# Print if available. \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsKetK1maxH3",
        "colab_type": "code",
        "outputId": "8a6389bc-f35c-4576-b2c1-110da73cbd15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "# install the required bert pretrained model\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 6.7MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/ae/b6d18c3f37da5a78e83701469e6153811f4b0ecb3f9387bb3e9a65ca48ee/pytorch_nlp-0.4.1-py3-none-any.whl (82kB)\n",
            "\r\u001b[K     |████                            | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 30.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 34.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 40kB 36.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 51kB 37.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 61kB 41.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 71kB 42.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 81kB 42.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 29.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Collecting regex (from pytorch-pretrained-bert)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.243)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (0.24.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.243)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->pytorch-nlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->pytorch-nlp) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->pytorch-nlp) (1.12.0)\n",
            "Installing collected packages: regex, pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.4.1 pytorch-pretrained-bert-0.6.2 regex-2019.8.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1hJQohhaz2U",
        "colab_type": "code",
        "outputId": "6346dc09-ae79-469e-e3fe-114e11ba02dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# if gpu is available set device equal to \"cuda\" else set it to \"cpu\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#get the name of the GPU\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOYH-hbDa9xi",
        "colab_type": "code",
        "outputId": "e8319372-62fb-4a6f-c9cb-93c2b8853ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Dropping that one Row having one row value as \"Label\"\n",
        "indexNames = fnd_df[ fnd_df['label'] == \"Label\" ].index\n",
        "indexNames\n",
        "fnd_df.drop(indexNames , inplace=True)\n",
        "fnd_df['label'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efdc1af3da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAELCAYAAAAybErdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOuzmpcRbC12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping 0:FAKE\n",
        "#   and   1:REAL\n",
        "# fnd_df.loc[:,'senti'] = fnd_df.label.map({'FAKE':0,'REAL':1})\n",
        "# fnd_df['senti'].astype(np.int64)\n",
        "fnd_df['label'] = fnd_df.label.map({'FAKE':0,'REAL':1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqISTEYPbMs-",
        "colab_type": "code",
        "outputId": "9a84bc25-eacb-4cf0-ea3d-9a7c8db64d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(fnd_df['label'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuPpZd-VebBR",
        "colab_type": "code",
        "outputId": "70544807-0153-4403-a7e3-831a98cf44a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "fnd_df['label'].astype(np.int64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-0f7a35e7d935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfnd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             raise ValueError('Cannot convert non-finite values (NA or inf) to '\n\u001b[0m\u001b[1;32m    677\u001b[0m                              'integer')\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYDVv_TmbO1W",
        "colab_type": "code",
        "outputId": "f6279fd4-204b-4559-ff15-bb89cf404d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# fnd_df = fnd_df.drop(['label'], axis=1)\n",
        "# fnd_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Four ways Bob Corker skewered Donald Trump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Linklater's war veteran comedy speaks to moder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trump’s Fight With Corker Jeopardizes His Legi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Egypt's Cheiron wins tie-up with Pemex for Mex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jason Aldean opens 'SNL' with Vegas tribute</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title\n",
              "0         Four ways Bob Corker skewered Donald Trump\n",
              "1  Linklater's war veteran comedy speaks to moder...\n",
              "2  Trump’s Fight With Corker Jeopardizes His Legi...\n",
              "3  Egypt's Cheiron wins tie-up with Pemex for Mex...\n",
              "4        Jason Aldean opens 'SNL' with Vegas tribute"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEFE1oBMbg7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the titles\n",
        "sentences = fnd_df.title.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DFxV8i4bpYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaGmTsTbrzj",
        "colab_type": "code",
        "outputId": "f12bf665-ea0c-4ef2-efb7-79d4b77793d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 929492.64B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'four', 'ways', 'bob', 'cork', '##er', 'sk', '##ew', '##ered', 'donald', 'trump', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_frPeaghbuGd",
        "colab_type": "code",
        "outputId": "055a758a-c43c-40d6-bfb9-a4469e41481b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#loading the labels value\n",
        "labels = fnd_df.label.values\n",
        "labels = labels.astype(np.int64)\n",
        "type(labels[0])\n",
        "# type(fnd_df['senti'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnTyaPLkgyaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels = labels.astype(np.int64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xShf-Rg-g2z2",
        "colab_type": "code",
        "outputId": "2a89a81d-8334-48ab-aad1-d122ab698929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(labels[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVlbyKytbzIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the maximum sequence length.\n",
        "#The longest sequence in our training set its 186\n",
        "# We will set it to 256\n",
        "\n",
        "MAX_LEN = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f529D5iVb1mC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thJ7JqNfb3nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbO-fITjb5oD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pad the sequences\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B5d7JFub7VT",
        "colab_type": "code",
        "outputId": "03c020b8-ae7c-4882-89a8-86a5d75482bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "#Printing to see how the second tweet after preprocessing looks.\n",
        "input_ids[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  4957, 13806,  2099,  1005,  1055,  2162,  8003,  4038,\n",
              "        8847,  2000,  2715,  2637,  1010,  2758,  2732,   102,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iml0XjWub9K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IVhP9UncA4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z66JulQRcG_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGdF9xqwcJIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task\n",
        "# A batch size of 16 or 32 is preferred \n",
        "# If Cuda goes out of memory try lowering the batch_size.\n",
        "batch_size = 15\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPquQE4VcOON",
        "colab_type": "code",
        "outputId": "256547b1-8583-4c44-b0af-7a6011a0cbc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "# We make the num_label = 2 REAL,FAKE\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:13<00:00, 29151287.58B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GAnYbSacSwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set different weight decays for different layers of the model.\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNYXHI3qcgWq",
        "colab_type": "code",
        "outputId": "d7d90207-59ce-4c76-fc8c-415551f73646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=3e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr41Nakrcjcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM1DHbDgclrk",
        "colab_type": "code",
        "outputId": "6b9c04a2-fb9c-4d19-a30c-4ff177ba96c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.21047700039078845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [39:36<5:56:26, 2376.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.728727556596409\n",
            "Train loss: 0.1438281285374651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [1:19:12<5:16:51, 2376.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7330210772833726\n",
            "Train loss: 0.11146654093818446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [1:58:56<4:37:29, 2378.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.731459797033568\n",
            "Train loss: 0.09226015377331709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [2:38:37<3:57:56, 2379.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7248243559718972\n",
            "Train loss: 0.07727984709746606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [3:18:15<3:18:14, 2378.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7252146760343476\n",
            "Train loss: 0.07570602036380669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [3:57:51<2:38:31, 2377.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.734192037470726\n",
            "Train loss: 0.0726501691920918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [4:37:26<1:58:51, 2377.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7224824355971899\n",
            "Train loss: 0.0863055489038733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [5:17:02<1:19:13, 2376.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7306791569086656\n",
            "Train loss: 0.1889206889433516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [5:56:32<39:34, 2374.88s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5132708821233413\n",
            "Train loss: 0.34522909695326687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 10/10 [6:36:08<00:00, 2375.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7127244340359096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK92RPgbcn2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}